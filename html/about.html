<h3>About</h3>
<p>This is a set of web pages on reworking some of the neural networks described in Andrew Trask's excellent book "<a href="https://www.amazon.co.uk/Grokking-Deep-Learning-Andrew-Trask/dp/1617293709/ref=sr_1_5?keywords=deep+learning&qid=1568656440&sr=8-5">Grokking Deep Learning</a>".
</p>
<p>What I find particularly noteworthy in Andrew's book is that he takes an algorithmic approach to learning neural networks over the more mathematical approach taken by other authors.  Andrew shows that one does not need to be able to derive the backpropagation algorithm ( the central core of all neural networks) from an understating of the calculus chain rule to implement it in code. While I do not downgrade a knowledge of calculus for fully understanding neural networks, Andrew shows that an algorithmic description of backpropagation is an excellent starting from which an understanding neural networks can be gained. This can then from a solid foundation both for moving forward with deep learning libraries and for going back to understand the mathematics.</p>
<p>In the final chapter of his book Andrew lays out 10 further steps to take in one's neural network education. Step 6 is that you should try and reverse engineer a network from an academic paper, see if you can improve on it, and then write about it. I am taking this approach to some of the networks in Andrew's book. I don't think I can improve on them but what I do want to do is reverse engineer them so that they are in pure python. In the networks that I recreate I will not use numpy. While numpy does indeed bring a marked improvement in the performance of matrix calculations it does so at the slight expense of obscuring the algorithmic behaviour of a neural net. As high speed networks can be best constructed using tensor libraries such as TensorFlow I feel the added clarity gained by using pure python more then makes up for the relative performance loss incured from not using numpy. This is purely a personal opinion and is in no way meant as a criticism of Andrews approach or his exclent book. </p>
<p>I will start my journey with the natural language network of chapter 11. This is a pure multi layer perseptron and forms the basis of understating the recurrent neural network of chapter 12 that I will tackle next</p>

